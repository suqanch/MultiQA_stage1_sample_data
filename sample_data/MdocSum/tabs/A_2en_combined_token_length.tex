\begin{table*}[t]
\caption{TS and OMatch Across Different Models and Token Length}
\centering
\resizebox{0.95\textwidth}{!}{
\begin{tabular}{l|cc|cc|cc|cc|cc|cc}
\toprule
\multirow{2}{*}{Model} & \multicolumn{2}{c|}{0\textasciitilde5k} & \multicolumn{2}{c|}{5\textasciitilde10k} & \multicolumn{2}{c|}{10\textasciitilde15k} & \multicolumn{2}{c|}{15\textasciitilde20k} & \multicolumn{2}{c|}{20\textasciitilde25k} & \multicolumn{2}{c}{25\textasciitilde30k} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11} \cmidrule(lr){12-13}
 & TS & OMatch & TS & OMatch & TS & OMatch & TS & OMatch & TS & OMatch & TS & OMatch \\
\midrule
GPT-4o & 0.594 & 0.688 & 0.605 & 0.547 & 0.608 & 0.514 & 0.600 & 0.552 & 0.621 & 0.381 & 0.609 & 0.414 \\
Gemini-Pro & 0.687 & 0.585 & 0.688 & 0.468 & 0.694 & 0.366 & 0.673 & 0.401 & 0.688 & 0.298 & 0.668 & 0.283 \\
Claude-3-5-Sonnet & 0.630 & 0.646 & 0.643 & 0.464 & 0.655 & 0.458 & 0.623 & 0.453 & 0.662 & 0.333 & 0.645 & 0.329 \\
Qwen2.5-VL-72B & 0.544 & 0.463 & 0.561 & 0.260 & 0.559 & 0.218 & 0.552 & 0.234 & 0.543 & 0.155 & 0.517 & 0.211 \\
Qwen2-VL-72B & 0.499 & 0.604 & 0.503 & 0.456 & 0.514 & 0.377 & 0.464 & 0.302 & 0.490 & 0.286 & 0.467 & 0.257 \\
Qwen2.5-VL-7B & 0.495 & 0.397 & 0.477 & 0.185 & 0.412 & 0.158 & 0.423 & 0.156 & 0.412 & 0.107 & 0.428 & 0.184 \\
Qwen2-VL-7B & 0.444 & 0.350 & 0.449 & 0.299 & 0.430 & 0.275 & 0.404 & 0.224 & 0.442 & 0.250 & 0.389 & 0.197 \\

\bottomrule
\end{tabular}
}
\label{tab:token}
\end{table*}